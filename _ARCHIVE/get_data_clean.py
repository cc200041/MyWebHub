import json
import re
import time
from deep_translator import GoogleTranslator

# --- é…ç½® ---
DB_FILE = "food_database.json"
BACKUP_FILE = "food_database_backup.json"

# åˆå§‹åŒ–å·¥å…·
try:
    import opencc
    cc = opencc.OpenCC('t2s')
    HAS_OPENCC = True
except:
    HAS_OPENCC = False

translator = GoogleTranslator(source='auto', target='zh-CN')

def is_chinese(text):
    """æ£€æŸ¥æ˜¯å¦åŒ…å«è‡³å°‘ä¸€ä¸ªæ±‰å­—"""
    return bool(re.search(r'[\u4e00-\u9fa5]', text))

def clean_name(name):
    """æ¸…ç†åç§°ä¸­çš„å¥‡æ€ªç¬¦å·"""
    # å»æ‰å¤šä½™çš„ç©ºæ ¼
    name = str(name).strip()
    # ç®€ç¹è½¬æ¢
    if HAS_OPENCC:
        name = cc.convert(name)
    return name

def process_database():
    if not os.path.exists(DB_FILE):
        print("âŒ æ‰¾ä¸åˆ° food_database.json")
        return

    print("ğŸ“‚ è¯»å–ç°æœ‰æ•°æ®åº“...")
    with open(DB_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # å¤‡ä»½ä¸€ä»½ï¼Œæ€•ä¸‡ä¸€åˆ å¤šäº†
    with open(BACKUP_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²å¤‡ä»½åŸæ•°æ®åˆ° {BACKUP_FILE}")

    cleaned_list = []
    removed_count = 0
    translated_count = 0

    print(f"ğŸ” å¼€å§‹æ¸…æ´— {len(data)} æ¡æ•°æ® (è¿™å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´)...")

    for item in data:
        original_name = item['name']
        name = clean_name(original_name)
        cal = item['cal']

        # 1. å·²ç»æ˜¯ä¸­æ–‡çš„ï¼Œä¿ç•™
        if is_chinese(name):
            item['name'] = name
            cleaned_list.append(item)
            continue

        # 2. å…¨æ˜¯è‹±æ–‡/å¤–æ–‡çš„ï¼Œå°è¯•ç¿»è¯‘
        try:
            # åªæœ‰çº¯å­—æ¯æ‰ç¿»è¯‘ï¼Œé¿å…ç¿»è¯‘ä¹±ç 
            print(f"   ç¿»è¯‘ä¸­: {name} ...", end="")
            trans = translator.translate(name)
            
            # ç¿»è¯‘æˆåŠŸä¸”åŒ…å«ä¸­æ–‡
            if trans and is_chinese(trans):
                print(f" -> [{trans}] (ä¿ç•™)")
                item['name'] = trans
                cleaned_list.append(item)
                translated_count += 1
                time.sleep(0.5) # ç¨å¾®æ…¢ç‚¹ï¼Œé˜²æ­¢å°IP
            else:
                # ç¿»è¯‘å®Œäº†è¿˜ä¸æ˜¯ä¸­æ–‡ï¼ˆæ¯”å¦‚å“ç‰Œå Ambpoeialï¼‰ï¼Œæˆ–è€…ç¿»è¯‘å¤±è´¥ -> åˆ é™¤ï¼
                print(f" -> ç¿»è¯‘æ— æ•ˆï¼Œåˆ é™¤ ğŸ—‘ï¸")
                removed_count += 1
        except Exception as e:
            print(f" -> ç¿»è¯‘å‡ºé”™ï¼Œåˆ é™¤ ğŸ—‘ï¸")
            removed_count += 1

    # 3. ä¿å­˜æ¸…æ´—åçš„æ•°æ®
    print("\nğŸ’¾ æ­£åœ¨ä¿å­˜...")
    # å»é‡
    unique_data = {v['name']: v for v in cleaned_list}.values()
    
    with open(DB_FILE, 'w', encoding='utf-8') as f:
        json.dump(list(unique_data), f, ensure_ascii=False, indent=2)

    print("-" * 30)
    print(f"ğŸ‰ æ¸…æ´—å®Œæˆï¼")
    print(f"ğŸ“‰ åŸæœ‰æ•°æ®: {len(data)} æ¡")
    print(f"ğŸ—‘ï¸ åˆ é™¤æ— æ•ˆ/çº¯è‹±æ–‡æ•°æ®: {removed_count} æ¡")
    print(f"ğŸ” æˆåŠŸç¿»è¯‘: {translated_count} æ¡")
    print(f"âœ… æœ€ç»ˆå‰©ä½™: {len(unique_data)} æ¡é«˜è´¨é‡æ•°æ®")

import os
if __name__ == "__main__":
    process_database()